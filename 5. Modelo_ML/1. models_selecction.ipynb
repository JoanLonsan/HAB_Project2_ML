{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a110ab-ae5b-475b-9b1f-8a460c45e685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold, LeaveOneOut, TimeSeriesSplit, RepeatedKFold\n",
    "\n",
    "# Modelos de regresion lineal\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "## Metricas\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error, classification_report,accuracy_score\n",
    "\n",
    "## Modelos de clasificacion\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99031922-04d3-4679-be46-c568603cce33",
   "metadata": {},
   "source": [
    "### SELECCION ENTRE DIEZ MODELOS DE CLASIFICACION CON VALIDACIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1a2f5-326d-4651-9222-3d3a66983194",
   "metadata": {},
   "source": [
    "### Recoleccion y division de datos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e426a12e-ae0a-480d-9d6c-1057b1699b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../4.3 csv_prep_ml/df_ml.csv')\n",
    "target_clas = 'next_class_encoded'\n",
    "target_reg = 'next_score'\n",
    "X = df.drop(columns=[target_clas, target_reg], axis = 1)\n",
    "y = df[target_clas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a000adeb-a8d4-4132-9125-7b6e0f218958",
   "metadata": {},
   "source": [
    "### Lista de modelos a probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2af380-e155-4112-b81b-06000f9ce4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42, n_jobs=-1)),\n",
    "    ('SVC', SVC(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_jobs=-1)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42, max_iter=500, n_jobs=-1)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "    ('MLP', MLPClassifier(random_state=42, max_iter=1000)),\n",
    "    ('Extra Trees', ExtraTreesClassifier(random_state=42, n_jobs=-1)),\n",
    "    ('Ridge Classifier', RidgeClassifier(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ef9a7-7ceb-4a0f-b138-13fa191c7a30",
   "metadata": {},
   "source": [
    "### Funcion para evaluar modelo con diferentes tecnicas de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b94b68-0570-48d8-be6f-49658c1012a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    results = {}\n",
    "    \n",
    "    # Holdout\n",
    "    accuracies = []\n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.80)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        accuracies.append(accuracy_test)\n",
    "    results['Holdout'] = np.mean(accuracies)\n",
    "    \n",
    "    # K-Fold Cross Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train_kf, X_val_kf = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_kf, y_val_kf = y.iloc[train_index], y.iloc[val_index]\n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "        y_pred_kf = model.predict(X_val_kf)\n",
    "        accuracies.append(accuracy_score(y_val_kf, y_pred_kf))\n",
    "    results['K-Fold'] = np.mean(accuracies)\n",
    "    \n",
    "    # Leave-One-Out Cross Validation (DEMASIADO TIEMPO DE PROCESAMIENTO!)\n",
    "    #loo = LeaveOneOut()\n",
    "    #accuracies = []\n",
    "    #for train_index, val_index in loo.split(X):\n",
    "    #    X_train_loo, X_val_loo = X.iloc[train_index], X.iloc[val_index]\n",
    "    #    y_train_loo, y_val_loo = y.iloc[train_index], y.iloc[val_index]\n",
    "    #    model.fit(X_train_loo, y_train_loo)\n",
    "    #    y_pred_loo = model.predict(X_val_loo)\n",
    "    #    accuracies.append(accuracy_score(y_val_loo, y_pred_loo))\n",
    "    #results['Leave-One-Out'] = np.mean(accuracies)\n",
    "    \n",
    "    # Time Series Split\n",
    "    tscv = TimeSeriesSplit()\n",
    "    accuracies = []\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train_tscv, X_val_tscv = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_tscv, y_val_tscv = y.iloc[train_index], y.iloc[val_index]\n",
    "        model.fit(X_train_tscv, y_train_tscv)\n",
    "        y_pred_tscv = model.predict(X_val_tscv)\n",
    "        accuracies.append(accuracy_score(y_val_tscv, y_pred_tscv))\n",
    "    results['TimeSeriesSplit'] = np.mean(accuracies)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61a078-82a6-476c-a747-5fac1a57ebe1",
   "metadata": {},
   "source": [
    "## Evaluar todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "292999d4-b99b-4703-8396-dfe708413678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: {'Holdout': 0.8937101449275363, 'K-Fold': 0.9039469089838243, 'TimeSeriesSplit': 0.9013937282229965}\n",
      "Random Forest: {'Holdout': 0.9244347826086957, 'K-Fold': 0.9245484949832775, 'TimeSeriesSplit': 0.9240418118466899}\n",
      "SVC: {'Holdout': 0.9142028985507247, 'K-Fold': 0.9149727603542205, 'TimeSeriesSplit': 0.9076655052264808}\n",
      "KNN: {'Holdout': 0.9189565217391304, 'K-Fold': 0.9184556488083968, 'TimeSeriesSplit': 0.9153310104529616}\n",
      "Logistic Regression: {'Holdout': 0.9199130434782608, 'K-Fold': 0.9216465787425591, 'TimeSeriesSplit': 0.9080139372822298}\n",
      "Naive Bayes: {'Holdout': 0.5627246376811594, 'K-Fold': 0.5679039145158915, 'TimeSeriesSplit': 0.2337979094076655}\n",
      "Gradient Boosting: {'Holdout': 0.9173913043478259, 'K-Fold': 0.9193256347152984, 'TimeSeriesSplit': 0.9149825783972126}\n",
      "MLP: {'Holdout': 0.9064927536231884, 'K-Fold': 0.9085858522117751, 'TimeSeriesSplit': 0.8979094076655052}\n",
      "Extra Trees: {'Holdout': 0.925710144927536, 'K-Fold': 0.9259986117246166, 'TimeSeriesSplit': 0.924738675958188}\n",
      "Ridge Classifier: {'Holdout': 0.9181739130434781, 'K-Fold': 0.9199053448602259, 'TimeSeriesSplit': 0.9156794425087108}\n"
     ]
    }
   ],
   "source": [
    "model_results = {}\n",
    "for name, model in models:\n",
    "    results = evaluate_model(model, X, y)\n",
    "    model_results[name] = results\n",
    "    print(f\"{name}: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34af43-a179-4bd7-94a2-ce75d297b400",
   "metadata": {},
   "source": [
    "## Seleccion de los dos mejores modelos segun el puntaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4796d2a8-249a-45c7-83c1-e12236a8b4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los dos mejores modelos: ['Extra Trees', 'Random Forest']\n"
     ]
    }
   ],
   "source": [
    "average_accuracies = {name: np.mean(list(scores.values())) for name, scores in model_results.items()}\n",
    "best_models = sorted(average_accuracies, key=average_accuracies.get, reverse=True)[:2]\n",
    "print(f\"Los dos mejores modelos: {best_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f70fb-327b-4e7f-9ad3-adce658d948b",
   "metadata": {},
   "source": [
    "## SELECCION ENTRE DIEZ MODELOS DE REGRESION CON VALIDACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79c0ba65-4a6c-4f4d-94e9-a89d78da38a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: {'Holdout': {'R2': -1.8602320112067177e+18, 'MAE': 277300798.2430181}, 'K-Fold': {'R2': -1.442444024833319e+17, 'MAE': 95428550.5573503}, 'Repeated K-Fold': {'R2': -8.396359857595414e+18, 'MAE': 457347688.0636404}}\n",
      "Ridge: {'Holdout': {'R2': 0.6501197041477269, 'MAE': 6.5390555623663715}, 'K-Fold': {'R2': 0.6539770049131249, 'MAE': 6.476879080410025}, 'Repeated K-Fold': {'R2': 0.6535813427719188, 'MAE': 6.469693274321204}}\n",
      "Lasso: {'Holdout': {'R2': 0.5177204328911443, 'MAE': 7.606174804124723}, 'K-Fold': {'R2': 0.5251808154536912, 'MAE': 7.535211326854449}, 'Repeated K-Fold': {'R2': 0.523624657577252, 'MAE': 7.543520487643691}}\n",
      "ElasticNet: {'Holdout': {'R2': 0.4080862550833421, 'MAE': 8.13218402226516}, 'K-Fold': {'R2': 0.41384970692326994, 'MAE': 8.087915595968711}, 'Repeated K-Fold': {'R2': 0.41341038712543104, 'MAE': 8.089355044042913}}\n",
      "Bayesian Ridge: {'Holdout': {'R2': 0.6502666964276881, 'MAE': 6.542433154917656}, 'K-Fold': {'R2': 0.6549560935629435, 'MAE': 6.477857302674562}, 'Repeated K-Fold': {'R2': 0.6544076767820024, 'MAE': 6.469030655395626}}\n",
      "Random Forest: {'Holdout': {'R2': 0.6778756782873817, 'MAE': 5.789841159420291}, 'K-Fold': {'R2': 0.6872023434183252, 'MAE': 5.714001585999453}, 'Repeated K-Fold': {'R2': 0.6840604646993859, 'MAE': 5.74027781914558}}\n",
      "SVR: {'Holdout': {'R2': 0.3361677374292076, 'MAE': 8.002362980895953}, 'K-Fold': {'R2': 0.3348907799912574, 'MAE': 7.979542074486692}, 'Repeated K-Fold': {'R2': 0.3355795251515105, 'MAE': 7.981626623766394}}\n",
      "Gradient Boosting: {'Holdout': {'R2': 0.6588704561440265, 'MAE': 6.304649506434066}, 'K-Fold': {'R2': 0.6676472590364769, 'MAE': 6.235816256685601}, 'Repeated K-Fold': {'R2': 0.6653433811554386, 'MAE': 6.225194590717938}}\n",
      "Hist Gradient Boosting: {'Holdout': {'R2': 0.673958664028832, 'MAE': 5.902068911472011}, 'K-Fold': {'R2': 0.6771184785570781, 'MAE': 5.875731175188421}, 'Repeated K-Fold': {'R2': 0.6782727727041364, 'MAE': 5.86931123108126}}\n",
      "Extra Trees: {'Holdout': {'R2': 0.6854259745166417, 'MAE': 5.505176231884057}, 'K-Fold': {'R2': 0.6930573684443884, 'MAE': 5.422587980900696}, 'Repeated K-Fold': {'R2': 0.6889793881625931, 'MAE': 5.461221809946503}}\n",
      "Los dos mejores modelos: ['Extra Trees', 'Random Forest']\n",
      "CPU times: total: 8min 52s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_preprocessed = pd.read_csv('../4.3 csv_prep_ml/df_ml.csv')\n",
    "X = df_preprocessed.drop(columns=['next_score']).values\n",
    "y = df_preprocessed['next_score'].values\n",
    "\n",
    "# Lista de modelos a probar\n",
    "models = [\n",
    "    ('Linear Regression', LinearRegression(n_jobs=-1)),\n",
    "    ('Ridge', Ridge(random_state=42)),\n",
    "    ('Lasso', Lasso(random_state=42)),\n",
    "    ('ElasticNet', ElasticNet(random_state=42)),\n",
    "    ('Bayesian Ridge', BayesianRidge()),\n",
    "    ('Random Forest', RandomForestRegressor(random_state=42, n_jobs=-1)),\n",
    "    ('SVR', SVR()),\n",
    "    ('Gradient Boosting', GradientBoostingRegressor(random_state=42)),\n",
    "    ('Hist Gradient Boosting', HistGradientBoostingRegressor(random_state=42)),\n",
    "    ('Extra Trees', ExtraTreesRegressor(random_state=42, n_jobs=-1))\n",
    "]\n",
    "# Función para evaluar el modelo con diferentes técnicas de validación\n",
    "def evaluate_model(model, X, y):\n",
    "    results = {}\n",
    "    \n",
    "    # Holdout\n",
    "    accuracies = []\n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        accuracies.append((r2_test, mae_test))\n",
    "    results['Holdout'] = {'R2': np.mean([a[0] for a in accuracies]), 'MAE': np.mean([a[1] for a in accuracies])}\n",
    "    \n",
    "    # K-Fold Cross Validation\n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    r2_scores = []\n",
    "    mae_scores = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train_kf, X_val_kf = X[train_index], X[val_index]\n",
    "        y_train_kf, y_val_kf = y[train_index], y[val_index]\n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "        y_pred_kf = model.predict(X_val_kf)\n",
    "        r2_scores.append(r2_score(y_val_kf, y_pred_kf))\n",
    "        mae_scores.append(mean_absolute_error(y_val_kf, y_pred_kf))\n",
    "    results['K-Fold'] = {'R2': np.mean(r2_scores), 'MAE': np.mean(mae_scores)}\n",
    "    \n",
    "    # Repeated K-Fold Cross Validation\n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    r2_scores_rkf = []\n",
    "    mae_scores_rkf = []\n",
    "    for train_index, val_index in rkf.split(X):\n",
    "        X_train_rkf, X_val_rkf = X[train_index], X[val_index]\n",
    "        y_train_rkf, y_val_rkf = y[train_index], y[val_index]\n",
    "        model.fit(X_train_rkf, y_train_rkf)\n",
    "        y_pred_rkf = model.predict(X_val_rkf)\n",
    "        r2_scores_rkf.append(r2_score(y_val_rkf, y_pred_rkf))\n",
    "        mae_scores_rkf.append(mean_absolute_error(y_val_rkf, y_pred_rkf))\n",
    "    results['Repeated K-Fold'] = {'R2': np.mean(r2_scores_rkf), 'MAE': np.mean(mae_scores_rkf)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluar todos los modelos\n",
    "model_results = {}\n",
    "for name, model in models:\n",
    "    results = evaluate_model(model, X, y)\n",
    "    model_results[name] = results\n",
    "    print(f\"{name}: {results}\")\n",
    "\n",
    "# Seleccionar los dos mejores modelos basados en el R2 promedio (mayor es mejor)\n",
    "average_r2 = {name: np.mean([scores['K-Fold']['R2'], scores['Repeated K-Fold']['R2']]) for name, scores in model_results.items()}\n",
    "best_models = sorted(average_r2, key=average_r2.get, reverse=True)[:2]\n",
    "print(f\"Los dos mejores modelos: {best_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e9239-fd03-4214-abf8-27e476736853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
